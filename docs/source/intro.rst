Introduction
============

**Data Transfer Framework (DTF)** is an I/O middleware designed for achieving scalable and high-speed data transfer between application components in multi-component workflows. 
Multi-component workflow is becoming a popular computation model in High Performance Computing (HPC), in which multiple independently developed application components are coupled together to perform more sophisticated and complex computations (e.g. data assimilation based weather prediction system).

In such workflows, massive computation data generated by a component during execution need to be transferred to the other as the input data to the subsequent computations.
However, the implementations of inter-component data exchange in most of the multi-compoenent systems are either based on file I/O through parallel file system or specifically designed tools called couplers.
Both of these approaches have pros and cons.
Because coupled application components are usually developed by different research teams, file I/O became the easiest approach, which exchanges data through file systems using high-performance parallel I/O libraries (e.g. PnetCDF and HDF5).
The major drawbacks of file I/O based approach are low speed and efficiency.


It is implemented using Message Passing Interface (MPI), which transparently redirects PnetCDF file I/O operations to DTF library implementations.

.. _fileio-dtf:

.. figure:: fileio-dtf.png
    :scale: 60%
    :align: center
    
    Difference between File I/O based and DTF based inter-component data exchange
